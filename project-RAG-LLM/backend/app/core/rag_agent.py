"""
RAG Agent æœåŠ¡å±‚ï¼ˆé‡æ„ç‰ˆï¼‰
==========================
èŒè´£ï¼š
- æŒ‰éœ€åˆ›å»º LangChain Retriever å’Œ Agentï¼ˆä¸å†ä½¿ç”¨ç¼“å­˜ï¼‰ã€‚
- æ”¯æŒåŠ¨æ€å‚æ•°é…ç½®ï¼ˆtemperature, top_k, messages_to_keepç­‰ï¼‰ã€‚
- é›†æˆçŸ­æœŸè®°å¿†ï¼ˆcheckpointerï¼‰å’Œè‡ªåŠ¨ Summarizationã€‚
- å¯¹å¤–æš´éœ²æ ‡å‡†è°ƒç”¨æ¥å£ï¼šinvokeï¼ˆä¸€æ¬¡æ€§ï¼‰ã€stream_updatesï¼ˆæ­¥éª¤æµï¼‰ã€stream_messagesï¼ˆä»…æ¨¡å‹æ–‡æœ¬ï¼‰ã€‚

è®°å¿†ç®¡ç†ï¼š
- ä½¿ç”¨ SQLite æ•°æ®åº“æŒä¹…åŒ–å¯¹è¯å†å²ï¼ˆå­˜å‚¨åœ¨ data/chat_memory.dbï¼‰ã€‚
- å½“ token æ•°è¶…è¿‡é˜ˆå€¼æ—¶ï¼Œè‡ªåŠ¨è§¦å‘ Summarization å‹ç¼©å†å²æ¶ˆæ¯ã€‚
- thread_id ç”¨äºåŒºåˆ†ä¸åŒä¼šè¯ï¼Œé»˜è®¤ä½¿ç”¨ "1"ã€‚

é‡æ„æ”¹è¿›ï¼š
- ç§»é™¤äº† _retriever_cache å’Œ _agent_cacheï¼Œè§£é™¤è¿‡åº¦è€¦åˆã€‚
- Agent å‚æ•°å¯åŠ¨æ€ä¼ é€’ï¼Œä¸å†è¢«é™æ€é…ç½®é”å®šã€‚
- æ¯æ¬¡è¯·æ±‚æŒ‰éœ€åˆ›å»º Agentï¼Œæ”¯æŒä¸åŒçš„ LLM å‚æ•°ã€‚
"""

import logging
import os
from typing import Iterator, List, Optional

from langchain_core.embeddings import Embeddings
from langchain.tools import tool
from langchain.agents import create_agent
from langchain.agents.middleware import SummarizationMiddleware
from .. import config
from ..services.embedding_service import EmbeddingService
from ..services.vector_store_repository import VectorStoreRepository
from .llm_handler import LLMHandler


logger = logging.getLogger(__name__)


# ---------------------------- Embeddings é€‚é…å™¨ ----------------------------
class LCEmbeddingAdapter(Embeddings):
    """å°†é¡¹ç›®å†…çš„ EmbeddingService é€‚é…ä¸º LangChain Embeddings æ¥å£ã€‚"""

    def __init__(self, service: EmbeddingService):
        self._service = service

    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        return self._service.embed_texts(texts)

    def embed_query(self, text: str) -> List[float]:
        return self._service.embed_text(text)


# ---------------------------- æ¨¡å—çº§ç¼“å­˜ ----------------------------
# åªä¿ç•™ Checkpointer ç¼“å­˜ï¼ˆçœŸæ­£æ˜‚è´µä¸”å…±äº«çš„èµ„æºï¼‰
_checkpointer = None


def _create_retriever_with_filter(session_id: str = "1", top_k: int = None ):
    """
    æ„å»ºä¸€ä¸ªå¸¦ session_id è¿‡æ»¤å’ŒåŠ¨æ€ K å€¼çš„ Retrieverï¼ˆæŒ‰éœ€åˆ›å»ºï¼Œä¸å†ç¼“å­˜ï¼‰ã€‚
    
    Args:
        session_id: å½“å‰ä¼šè¯IDï¼Œé»˜è®¤ "1"
        top_k: æ£€ç´¢æ–‡æ¡£æ•°é‡ï¼Œè‹¥ä¸º None åˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶é»˜è®¤å€¼
        
    æ£€ç´¢èŒƒå›´ï¼š
        - session_id = "system" çš„æ–‡æ¡£ï¼ˆå…¨å±€ç³»ç»Ÿæ–‡æ¡£ï¼‰
        - session_id = å½“å‰ä¼šè¯ID çš„æ–‡æ¡£ï¼ˆç”¨æˆ·ä¸Šä¼ çš„æ–‡æ¡£ï¼‰
    """
    # ä½¿ç”¨ä¼ å…¥çš„ top_kï¼Œè‹¥æœªæŒ‡å®šåˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶é»˜è®¤å€¼
    if top_k is None:
        top_k = config.RAG_TOP_K
    
    embedding_service = EmbeddingService.get_instance()
    vector_repo = VectorStoreRepository()
    lc_embeddings = LCEmbeddingAdapter(embedding_service)
    
    # æ„å»ºè¿‡æ»¤æ¡ä»¶ï¼šæ£€ç´¢ system æ–‡æ¡£ + å½“å‰ä¼šè¯æ–‡æ¡£
    search_kwargs = {
        "k": top_k,
        "filter": {
            "$or": [
                {"session_id": "system"},      # ç³»ç»Ÿå…¨å±€æ–‡æ¡£
                {"session_id": session_id}     # å½“å‰ä¼šè¯æ–‡æ¡£
            ]
        }
    }
    
    logger.info(f"ğŸ”¨ åˆ›å»ºæ–°çš„ retrieverï¼Œsession_id={session_id}, top_k={top_k}")
    retriever = vector_repo.as_langchain_retriever(
        embedding_instance=lc_embeddings,
        search_type="similarity",
        search_kwargs=search_kwargs,
    )
    
    return retriever


def _get_checkpointer():
    """æ„å»ºæˆ–è¿”å›ç¼“å­˜çš„ Checkpointerï¼ˆç”¨äºçŸ­æœŸè®°å¿†æŒä¹…åŒ–ï¼‰ã€‚"""
    global _checkpointer
    if _checkpointer is not None:
        return _checkpointer
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    db_dir = os.path.dirname(config.CHAT_MEMORY_DB_PATH)
    if db_dir:
        os.makedirs(db_dir, exist_ok=True)
    
    # å°è¯•ä½¿ç”¨ SQLite Checkpointerï¼ˆéœ€è¦ langgraph-checkpoint-sqliteï¼‰
    # å¦‚æœä¸å¯ç”¨ï¼Œé™çº§åˆ° MemorySaverï¼ˆå†…å­˜å­˜å‚¨ï¼‰
    try:
        try:
            from langgraph.checkpoint.sqlite import SqliteSaver
            import sqlite3
            conn = sqlite3.connect(config.CHAT_MEMORY_DB_PATH, check_same_thread=False)
            _checkpointer = SqliteSaver(conn)
            _checkpointer.setup()
            logger.info(f"ä½¿ç”¨ SQLite Checkpointerï¼Œæ•°æ®åº“è·¯å¾„: {config.CHAT_MEMORY_DB_PATH}")
        except Exception as e:
            logger.error(
                "åˆå§‹åŒ– SqliteSaver å¤±è´¥ï¼Œå°†é™çº§ä¸º MemorySaverã€‚é”™è¯¯: %s: %s",
                type(e).__name__, str(e), exc_info=True
            )
            from langgraph.checkpoint.memory import MemorySaver
            _checkpointer = MemorySaver()
            logger.warning("å·²åˆ‡æ¢ä¸º MemorySaverï¼ˆå†…å­˜å­˜å‚¨ï¼Œé‡å¯åä¸¢å¤±ï¼‰ã€‚")
    except Exception as e:
        from langgraph.checkpoint.memory import MemorySaver
        _checkpointer = MemorySaver()
        logger.warning(f"åˆå§‹åŒ– Checkpointer å¤±è´¥: {e}ï¼Œä½¿ç”¨ MemorySaverï¼ˆå†…å­˜å­˜å‚¨ï¼‰")
    
    return _checkpointer


def _create_dynamic_agent(
    session_id: str,
    temperature: float = None,
    top_k: int = None,
    messages_to_keep: int = None,
    max_tokens: int = None,
):
    """
    æ ¹æ®ä¼ å…¥çš„åŠ¨æ€å‚æ•°ï¼ŒæŒ‰éœ€åˆ›å»ºä¸€ä¸ªæ–°çš„ Agent å®ä¾‹ï¼ˆä¸å†ç¼“å­˜ï¼‰ã€‚
    
    Args:
        session_id: ä¼šè¯IDï¼Œç”¨äºæ–‡æ¡£æ£€ç´¢è¿‡æ»¤
        temperature: LLM æ¸©åº¦å‚æ•°ï¼Œè‹¥ä¸º None åˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶é»˜è®¤å€¼
        top_k: RAG æ£€ç´¢çš„ K å€¼ï¼Œè‹¥ä¸º None åˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶é»˜è®¤å€¼
        messages_to_keep: è®°å¿†å‹ç¼©åä¿ç•™çš„æ¶ˆæ¯æ•°ï¼Œè‹¥ä¸º None åˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶é»˜è®¤å€¼
        max_tokens: æœ€å¤§ç”Ÿæˆtokenæ•°ï¼Œè‹¥ä¸º None åˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶é»˜è®¤å€¼
    
    Returns:
        é…ç½®å¥½çš„ Agent å®ä¾‹
    """
    # --- 1. å¤„ç†åŠ¨æ€å‚æ•°ï¼Œè®¾ç½®é»˜è®¤å€¼ ---
    
    # LLM å‚æ•°
    effective_temperature = temperature if temperature is not None else getattr(config, 'RAG_TEMPERATURE', 0.2)
    
    # Retriever å‚æ•°
    effective_top_k = top_k if top_k is not None else config.RAG_TOP_K
    
    #Max Tokens å‚æ•°
    effective_max_tokens = max_tokens if max_tokens is not None else config.LLM_MAX_TOKENS
    
    # Memory (Summarization) å‚æ•°
    effective_messages_to_keep = messages_to_keep if messages_to_keep is not None else config.MEMORY_MESSAGES_TO_KEEP
    
    # ã€ä¿®æ­£ã€‘æ‘˜è¦é˜ˆå€¼ *å¿…é¡»* å§‹ç»ˆæ¥è‡ª configï¼Œå®ƒä¸æ˜¯ä¸€ä¸ªåŠ¨æ€å‚æ•°
    summarization_threshold = config.MEMORY_MAX_TOKENS_BEFORE_SUMMARY
    
    # --- 2. è·å–åŸºç¡€ LLM å¹¶ç»‘å®šåŠ¨æ€å‚æ•° ---
    base_llm = LLMHandler.get_instance().get_model()
    
    # ã€ä¿®æ­£1ã€‘æ”¶é›†æ‰€æœ‰è¦ç»‘å®šçš„ LLM å‚æ•°
    llm_params_to_bind = {
        "temperature": effective_temperature,
        "max_tokens": effective_max_tokens
    }

    llm = base_llm.bind(**llm_params_to_bind)
    
    # --- 3. è·å–å…±äº«çš„ Checkpointer ---
    checkpointer = _get_checkpointer()
    
    # --- 4. åˆ›å»ºåŠ¨æ€ Summarization Middleware ---
    # ã€ä¿®æ­£2ã€‘ä½¿ç”¨æ­£ç¡®çš„é…ç½®é¡¹
    summarization_middleware = SummarizationMiddleware(
        model=llm,
        max_tokens_before_summary=summarization_threshold,  #è®°å¿†æ‘˜è¦é˜ˆå€¼
        messages_to_keep=effective_messages_to_keep,#ç”¨äºæ§åˆ¶è®°å¿†å‹ç¼©åä¿ç•™çš„æ¶ˆæ¯æ•°
    )

    logger.info(
        f"ğŸ”¨ åˆ›å»ºæ–°çš„ Agentï¼Œsession_id={session_id}, "
        f"temperature={effective_temperature}, top_k={effective_top_k}, "
        f"max_generation_tokens={max_tokens}, "
        f"summary_threshold={summarization_threshold}, "
        f"messages_to_keep={effective_messages_to_keep}"
    )
    
    # --- 5. åˆ›å»ºåŠ¨æ€ Retriever ---
    retriever = _create_retriever_with_filter(
        session_id=session_id,
        top_k=effective_top_k
    )
    
    # --- 6. åŠ¨æ€åˆ›å»ºå·¥å…·ï¼ˆé—­åŒ…ï¼‰ ---
    @tool("retrieve_context", response_format="content_and_artifact")
    def retrieve_context_filtered(query: str):
        """æ£€ç´¢ä¸é—®é¢˜ç›¸å…³çš„ä¸Šä¸‹æ–‡å†…å®¹ï¼ˆé™å®šå½“å‰ä¼šè¯èŒƒå›´ï¼šç³»ç»Ÿæ–‡æ¡£+ç”¨æˆ·ä¸Šä¼ æ–‡æ¡£ï¼‰ã€‚"""
        docs = retriever.invoke(query)
        serialized = "\n\n".join(
            (
                f"Source: {doc.metadata.get('source', '<unknown>')}\n"
                f"Session: {doc.metadata.get('session_id', 'unknown')}\n"
                f"Content: {doc.page_content}"
                for doc in docs
            )
        )
        return serialized, docs
    
    # --- 7. System Prompt ---
    system_prompt = (
        "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é—®ç­”åŠ©æ‰‹ã€‚ä½ æœ‰ä¸€ä¸ªç”¨äºæ£€ç´¢ä¸Šä¸‹æ–‡çš„å·¥å…· `retrieve_context`ã€‚\n\n"
        "**æ ¸å¿ƒè§„åˆ™**:\n"
        "** ä½ éœ€è¦åˆ¤æ–­é—®é¢˜æ˜¯å¦éœ€è¦å¤–éƒ¨çŸ¥è¯†ï¼Œè‹¥éœ€è¦ï¼Œåˆ™ä¸¥æ ¼éµå®ˆä»¥ä¸‹è§„åˆ™ï¼š** "
        "1. åœ¨å›ç­”å‰ï¼Œä½ **å¿…é¡»**è°ƒç”¨ `retrieve_context` å·¥å…·ã€‚\n"
        "2. ä½ **å¿…é¡»åªä½¿ç”¨**è¯¥å·¥å…·è¿”å›çš„\"ä¸Šä¸‹æ–‡ä¿¡æ¯\"æ¥å›ç­”é—®é¢˜ã€‚\n"
        "3. **ä¸¥ç¦**ä½¿ç”¨ä½ çš„å†…éƒ¨çŸ¥è¯†æˆ–ä¸ªäººè§è§£æ¥ç¼–é€ ç­”æ¡ˆã€‚\n"
        "4. å¦‚æœå·¥å…·è¿”å›çš„\"ä¸Šä¸‹æ–‡ä¿¡æ¯\"ä¸è¶³ä»¥å›ç­”ï¼Œè¯·**ç›´æ¥**å›å¤ï¼š'æ ¹æ®æˆ‘æ‰€æŒæ¡çš„èµ„æ–™ï¼Œæ— æ³•å›ç­”æ‚¨çš„é—®é¢˜ã€‚'\n\n"

        "**å¼•ç”¨ä¸æ ¼å¼è¦æ±‚ **:\n"
        "1. è‹¥ä½ å¼•ç”¨äº†å¤–éƒ¨èµ„æ–™ï¼Œåˆ™ä½ çš„å›ç­”**å¿…é¡»**åŸºäºå·¥å…·è¿”å›çš„å†…å®¹ `Content`ã€‚\n"
        "2. åœ¨å›ç­”çš„**æœ€å**ï¼Œä½ **å¿…é¡»**å¦èµ·ä¸€æ®µï¼Œä»¥ '**å‚è€ƒèµ„æ–™**' ä¸ºæ ‡é¢˜ï¼Œå¹¶ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼åˆ—å‡ºä½ å‚è€ƒçš„*æ‰€æœ‰*æ¥æºï¼š\n"
        "   ```\n"
        "   Source: [è¿™é‡Œå¡«å…¥ä½ çœ‹åˆ°çš„ Source]\n"
        "   Content: [è¿™é‡Œå¡«å…¥ä½ å¼•ç”¨çš„ Content ç¼©å†™æˆ–ç‰‡æ®µã€‚å¤§çº¦50å­—]\n"
        "   ```\n"
        "   ä¾‹å¦‚ï¼š\n"
        "   **å‚è€ƒèµ„æ–™**\n"
        "   ```\n"
        "   Source: manual.pdf\n"
        "   Content: è¿™æ˜¯ç¬¬ä¸€ä»½æ–‡æ¡£å†…å®¹...\n"
        "   ```\n"
        "   ```\n"
        "   Source: guide.txt\n"
        "   Content: è¿™æ˜¯ç¬¬äºŒä»½æ–‡æ¡£å†…å®¹...\n"
        "   ```\n"
        "3. å¿…é¡»ä½¿ç”¨è§„èŒƒçš„ Markdown æ ¼å¼ã€‚"
    )
    
    # --- 8. åˆ›å»º Agent ---
    agent = create_agent(
        llm,
        tools=[retrieve_context_filtered],
        system_prompt=system_prompt,
        checkpointer=checkpointer,
        middleware=[summarization_middleware],
    )
    
    logger.info(f"âœ… åŠ¨æ€ Agent å·²åˆ›å»ºï¼ˆsession_id={session_id})")
    
    return agent



# ---------------------------- å¯¹å¤–æ¥å£ ----------------------------
def invoke(
    question: str, 
    thread_id: str = "1", 
    timeout_s: Optional[float] = None,
    temperature: float = None,
    top_k: int = None,
    messages_to_keep: int = None,
    max_tokens: int = None
) -> str:
    """
    ä¸€æ¬¡æ€§è°ƒç”¨ï¼Œè¿”å›å®Œæ•´å›ç­”æ–‡æœ¬ã€‚
    
    Args:
        question: ç”¨æˆ·é—®é¢˜
        thread_id: å¯¹è¯çº¿ç¨‹IDï¼Œç”¨äºåŒºåˆ†ä¸åŒä¼šè¯å’Œæ–‡æ¡£æ£€ç´¢èŒƒå›´ï¼ˆé»˜è®¤ "1"ï¼‰
        timeout_s: è¶…æ—¶æ—¶é—´ï¼ˆæš‚æœªä½¿ç”¨ï¼‰
        temperature: LLM æ¸©åº¦å‚æ•°
        top_k: RAG æ£€ç´¢çš„ K å€¼
        messages_to_keep: è®°å¿†å‹ç¼©åä¿ç•™çš„æ¶ˆæ¯æ•°
        max_tokens: æœ€å¤§ç”Ÿæˆtokenæ•°
    
    Returns:
        å®Œæ•´å›ç­”æ–‡æœ¬
    """
    agent = _create_dynamic_agent(
        session_id=thread_id,
        temperature=temperature,
        top_k=top_k,
        messages_to_keep=messages_to_keep,
        max_tokens=max_tokens
    )
    config_dict = {"configurable": {"thread_id": thread_id}}
    
    # é‡‡ç”¨ messages æµï¼Œåªæ‹¼æ¥æ¨¡å‹æ–‡æœ¬å—
    parts: List[str] = []
    for token, meta in agent.stream(
        {"messages": [{"role": "user", "content": question}]},
        stream_mode="messages",
        config=config_dict,
    ):
        if isinstance(meta, dict) and meta.get("langgraph_node") != "model":
            continue
        for block in getattr(token, "content_blocks", []) or []:
            if isinstance(block, dict) and block.get("type") == "text":
                text = block.get("text", "")
                if text:
                    parts.append(text)
    return "".join(parts)


def stream_updates(
    question: str, 
    thread_id: str = "1",
    temperature: float = None,
    top_k: int = None,
    messages_to_keep: int = None
):
    """
    æ­¥éª¤çº§æµï¼ˆmodel â†’ tools â†’ modelï¼‰ã€‚äº§å‡º dictï¼Œä¾¿äºè°ƒè¯•ä¸è§‚æµ‹ã€‚
    
    Args:
        question: ç”¨æˆ·é—®é¢˜
        thread_id: å¯¹è¯çº¿ç¨‹IDï¼Œç”¨äºåŒºåˆ†ä¸åŒä¼šè¯å’Œæ–‡æ¡£æ£€ç´¢èŒƒå›´ï¼ˆé»˜è®¤ "1"ï¼‰
        temperature: LLM æ¸©åº¦å‚æ•°
        top_k: RAG æ£€ç´¢çš„ K å€¼
        messages_to_keep: è®°å¿†å‹ç¼©åä¿ç•™çš„æ¶ˆæ¯æ•°
    
    Yields:
        æ­¥éª¤æ›´æ–°å­—å…¸
    """
    agent = _create_dynamic_agent(
        session_id=thread_id,
        temperature=temperature,
        top_k=top_k,
        messages_to_keep=messages_to_keep
    )
    config_dict = {"configurable": {"thread_id": thread_id}}
    for chunk in agent.stream(
        {"messages": [{"role": "user", "content": question}]},
        stream_mode="updates",
        config=config_dict,
    ):
        yield chunk


def stream_messages(
    question: str, 
    thread_id: str = "1",
    temperature: float = None,
    top_k: int = None,
    messages_to_keep: int = None,
    max_tokens: int = None,
):
    """
    ä»…æµå¼è¾“å‡ºæ¨¡å‹æ–‡æœ¬å—ï¼ˆé€æ®µï¼‰ã€‚äº§å‡º strã€‚
    
    Args:
        question: ç”¨æˆ·é—®é¢˜
        thread_id: å¯¹è¯çº¿ç¨‹IDï¼Œç”¨äºåŒºåˆ†ä¸åŒä¼šè¯å’Œæ–‡æ¡£æ£€ç´¢èŒƒå›´ï¼ˆé»˜è®¤ "1"ï¼‰
        temperature: LLM æ¸©åº¦å‚æ•°
        top_k: RAG æ£€ç´¢çš„ K å€¼
        messages_to_keep: è®°å¿†å‹ç¼©åä¿ç•™çš„æ¶ˆæ¯æ•°
        max_tokens: æœ€å¤§ç”Ÿæˆtokenæ•°
    
    Yields:
        æ–‡æœ¬å—å­—ç¬¦ä¸²
    """
    agent = _create_dynamic_agent(
        session_id=thread_id,
        temperature=temperature,
        top_k=top_k,
        messages_to_keep=messages_to_keep,
        max_tokens=max_tokens
    )
    config_dict = {"configurable": {"thread_id": thread_id}}
    for token, meta in agent.stream(
        {"messages": [{"role": "user", "content": question}]},
        stream_mode="messages",
        config=config_dict,
    ):
        if isinstance(meta, dict) and meta.get("langgraph_node") != "model":
            continue
        blocks = getattr(token, "content_blocks", None)
        if not blocks:
            continue
        for block in blocks:
            if isinstance(block, dict) and block.get("type") == "text":
                text = block.get("text", "")
                if text:
                    yield text
